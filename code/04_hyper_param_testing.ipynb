{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter testing\n",
    "\n",
    "In this section of the code we will try to fine tune our model to get better results.\n",
    "\n",
    "<hr />\n",
    "\n",
    "Import cleaned and aggreated data from [02_data_cleaning_and_aggregation.ipynb](./02_data_cleaning_and_aggregation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df=pd.read_json(\"./datasets/generated/cleaned_aggregated_data_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>averageWinRate</th>\n",
       "      <th>averagePoints</th>\n",
       "      <th>averageRebounds</th>\n",
       "      <th>averageAssists</th>\n",
       "      <th>averageSteals</th>\n",
       "      <th>averageBlocks</th>\n",
       "      <th>averageTurnovers</th>\n",
       "      <th>averageFGRatio</th>\n",
       "      <th>averageFTRatio</th>\n",
       "      <th>averageThreeRatio</th>\n",
       "      <th>coachWinRate</th>\n",
       "      <th>numberOfAwardedPlayers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>222.360859</td>\n",
       "      <td>101.006193</td>\n",
       "      <td>40.109001</td>\n",
       "      <td>22.393889</td>\n",
       "      <td>10.068126</td>\n",
       "      <td>42.180842</td>\n",
       "      <td>0.409265</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>0.253256</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WAS</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>229.818750</td>\n",
       "      <td>101.212500</td>\n",
       "      <td>52.352083</td>\n",
       "      <td>24.168750</td>\n",
       "      <td>9.056250</td>\n",
       "      <td>46.260417</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.775180</td>\n",
       "      <td>0.326570</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAS</td>\n",
       "      <td>8</td>\n",
       "      <td>N</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>208.948315</td>\n",
       "      <td>87.485393</td>\n",
       "      <td>40.890637</td>\n",
       "      <td>23.185019</td>\n",
       "      <td>8.444944</td>\n",
       "      <td>38.629213</td>\n",
       "      <td>0.421434</td>\n",
       "      <td>0.746699</td>\n",
       "      <td>0.342584</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAS</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>234.080838</td>\n",
       "      <td>98.093812</td>\n",
       "      <td>57.265469</td>\n",
       "      <td>25.990519</td>\n",
       "      <td>12.104291</td>\n",
       "      <td>47.100798</td>\n",
       "      <td>0.423451</td>\n",
       "      <td>0.748017</td>\n",
       "      <td>0.347804</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAS</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>208.569231</td>\n",
       "      <td>96.557265</td>\n",
       "      <td>45.564103</td>\n",
       "      <td>22.707692</td>\n",
       "      <td>11.046154</td>\n",
       "      <td>40.806838</td>\n",
       "      <td>0.398834</td>\n",
       "      <td>0.694540</td>\n",
       "      <td>0.337006</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CHA</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>221.324885</td>\n",
       "      <td>99.687623</td>\n",
       "      <td>50.847597</td>\n",
       "      <td>24.255431</td>\n",
       "      <td>11.236011</td>\n",
       "      <td>42.470046</td>\n",
       "      <td>0.423319</td>\n",
       "      <td>0.749351</td>\n",
       "      <td>0.323474</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CHA</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>206.986888</td>\n",
       "      <td>93.321678</td>\n",
       "      <td>47.524913</td>\n",
       "      <td>24.971591</td>\n",
       "      <td>10.012238</td>\n",
       "      <td>43.409528</td>\n",
       "      <td>0.414555</td>\n",
       "      <td>0.791145</td>\n",
       "      <td>0.434595</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>CHA</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>195.899778</td>\n",
       "      <td>75.541420</td>\n",
       "      <td>53.237056</td>\n",
       "      <td>21.937500</td>\n",
       "      <td>8.870192</td>\n",
       "      <td>44.350592</td>\n",
       "      <td>0.407616</td>\n",
       "      <td>0.758836</td>\n",
       "      <td>0.287525</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>187.791463</td>\n",
       "      <td>94.755002</td>\n",
       "      <td>44.626501</td>\n",
       "      <td>19.664295</td>\n",
       "      <td>10.381948</td>\n",
       "      <td>42.261450</td>\n",
       "      <td>0.434338</td>\n",
       "      <td>0.708438</td>\n",
       "      <td>0.393790</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>ATL</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>193.078571</td>\n",
       "      <td>82.600000</td>\n",
       "      <td>40.688095</td>\n",
       "      <td>18.550000</td>\n",
       "      <td>7.564286</td>\n",
       "      <td>41.083333</td>\n",
       "      <td>0.436712</td>\n",
       "      <td>0.706352</td>\n",
       "      <td>0.315101</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year playoff  averageWinRate  averagePoints  averageRebounds  \\\n",
       "0    WAS    10       Y        0.470588     222.360859       101.006193   \n",
       "1    WAS     9       N        0.529412     229.818750       101.212500   \n",
       "2    WAS     8       N        0.470588     208.948315        87.485393   \n",
       "3    WAS     7       Y        0.500000     234.080838        98.093812   \n",
       "4    WAS     6       N        0.264706     208.569231        96.557265   \n",
       "..   ...   ...     ...             ...            ...              ...   \n",
       "105  CHA     5       N        0.562500     221.324885        99.687623   \n",
       "106  CHA     4       Y        0.562500     206.986888        93.321678   \n",
       "107  CHA     3       Y        0.250000     195.899778        75.541420   \n",
       "108  ATL    10       Y        0.500000     187.791463        94.755002   \n",
       "109  ATL     9       N        0.500000     193.078571        82.600000   \n",
       "\n",
       "     averageAssists  averageSteals  averageBlocks  averageTurnovers  \\\n",
       "0         40.109001      22.393889      10.068126         42.180842   \n",
       "1         52.352083      24.168750       9.056250         46.260417   \n",
       "2         40.890637      23.185019       8.444944         38.629213   \n",
       "3         57.265469      25.990519      12.104291         47.100798   \n",
       "4         45.564103      22.707692      11.046154         40.806838   \n",
       "..              ...            ...            ...               ...   \n",
       "105       50.847597      24.255431      11.236011         42.470046   \n",
       "106       47.524913      24.971591      10.012238         43.409528   \n",
       "107       53.237056      21.937500       8.870192         44.350592   \n",
       "108       44.626501      19.664295      10.381948         42.261450   \n",
       "109       40.688095      18.550000       7.564286         41.083333   \n",
       "\n",
       "     averageFGRatio  averageFTRatio  averageThreeRatio  coachWinRate  \\\n",
       "0          0.409265        0.766500           0.253256      0.500000   \n",
       "1          0.430233        0.775180           0.326570      0.500000   \n",
       "2          0.421434        0.746699           0.342584      0.470588   \n",
       "3          0.423451        0.748017           0.347804      0.437500   \n",
       "4          0.398834        0.694540           0.337006      0.470588   \n",
       "..              ...             ...                ...           ...   \n",
       "105        0.423319        0.749351           0.323474      0.500000   \n",
       "106        0.414555        0.791145           0.434595      0.500000   \n",
       "107        0.407616        0.758836           0.287525      0.281250   \n",
       "108        0.434338        0.708438           0.393790      0.500000   \n",
       "109        0.436712        0.706352           0.315101      0.500000   \n",
       "\n",
       "     numberOfAwardedPlayers  \n",
       "0                         0  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  \n",
       "..                      ...  \n",
       "105                       0  \n",
       "106                       0  \n",
       "107                       0  \n",
       "108                       5  \n",
       "109                       2  \n",
       "\n",
       "[110 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "### Testing some attributes with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6060606060606061\n",
      "SVM Accuracy: 0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are your training and testing data\n",
    "# X_train and X_test should be your feature matrices, and y_train and y_test should be your target labels (0 or 1)\n",
    "features=['averagePoints','averageRebounds','averageAssists','averageFGRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "target = 'playoff'\n",
    "x = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_predictions = logreg.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear')  # You can change the kernel as needed (e.g., 'rbf' for radial basis function)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_predictions = svm.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 year offset results\n",
    "\n",
    "Logistic Regression Accuracy: 0.631578947368421\n",
    "\n",
    "SVM Accuracy: 0.6842105263157895\n",
    "\n",
    "#### 2 year offset results\n",
    "\n",
    "Logistic Regression Accuracy: 0.6060606060606061\n",
    "\n",
    "SVM Accuracy: 0.6060606060606061"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing all attributes with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6363636363636364\n",
      "SVM Accuracy: 0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are your training and testing data\n",
    "# X_train and X_test should be your feature matrices, and y_train and y_test should be your target labels (0 or 1)\n",
    "features=['averageWinRate', 'averagePoints','averageRebounds','averageAssists', 'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio', 'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "target = 'playoff'\n",
    "x = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_predictions = logreg.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear')  # You can change the kernel as needed (e.g., 'rbf' for radial basis function)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_predictions = svm.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 year offset results\n",
    "\n",
    "Logistic Regression Accuracy: 0.6842105263157895\n",
    "\n",
    "SVM Accuracy: 0.6842105263157895\n",
    "\n",
    "#### 2 year offset results\n",
    "\n",
    "Logistic Regression Accuracy: 0.6363636363636364\n",
    "\n",
    "SVM Accuracy: 0.6060606060606061"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning and testing\n",
    "\n",
    "#### Fine tuning on random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Combination: ['averageWinRate', 'averagePoints', 'averageTurnovers']\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
      "Best Model Accuracy: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "features = ['averageWinRate', 'averagePoints', 'averageRebounds', 'averageAssists', \n",
    "            'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio', \n",
    "            'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "\n",
    "target = 'playoff'  \n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_feature_combination = None\n",
    "\n",
    "# Iterate through all possible feature combinations\n",
    "for i in tqdm(range(1, len(features) + 1)):\n",
    "    for subset in combinations(features, i):\n",
    "        selected_features = list(subset)\n",
    "        X_train_subset = X_train[selected_features]\n",
    "        X_test_subset = X_test[selected_features]\n",
    "        \n",
    "        # Define hyperparameters and their possible values to search\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'penalty': ['l2']\n",
    "        }\n",
    "        \n",
    "        # Create a Logistic Regression model\n",
    "        model = LogisticRegression(solver='liblinear')\n",
    "        \n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "        grid_search.fit(X_train_subset, y_train)\n",
    "        \n",
    "        # Get the best parameters and the best model\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        accuracy = best_model.score(X_test_subset, y_test)\n",
    "        \n",
    "        # Check if this combination is the best so far\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_feature_combination = selected_features\n",
    "            best_hyperparameters = best_params\n",
    "\n",
    "print(\"Best Feature Combination:\", best_feature_combination)\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Model Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 year offset results\n",
    "\n",
    "Best Feature Combination: ['averageWinRate', 'averageRebounds', 'averageAssists', 'averageTurnovers', 'averageFGRatio', 'coachWinRate']\n",
    "\n",
    "Best Hyperparameters: {'C': 1, 'penalty': 'l2'}\n",
    "\n",
    "Best Model Accuracy: 0.8157894736842105\n",
    "\n",
    "#### 2 year offset results\n",
    "\n",
    "Best Feature Combination: ['averageWinRate', 'averagePoints', 'averageTurnovers']\n",
    "\n",
    "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
    "\n",
    "Best Model Accuracy: 0.7575757575757576\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning on split by years (train on oldest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  75.45 %\n",
      "X_test:  24.55 %\n",
      "y_train:  75.45 %\n",
      "y_test:  24.55 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [05:16<00:00, 24.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Combination: ['averageBlocks', 'averageFGRatio', 'averageFTRatio']\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
      "Best Model Accuracy: 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['year', 'averageWinRate', 'averagePoints', 'averageRebounds', 'averageAssists', \n",
    "            'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio', \n",
    "            'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "\n",
    "target = 'playoff'  \n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "#Split dataset in such way that we use latest years for training and older years for testing\n",
    "X_train=df[df[\"year\"]<9][features]\n",
    "X_test=df[df[\"year\"]>=9][features]\n",
    "y_train=df[df[\"year\"]<9][\"playoff\"]\n",
    "y_test=df[df[\"year\"]>=9][\"playoff\"]\n",
    "\n",
    "# Get percentage of data in each dataset\n",
    "print(\"X_train: \", round((len(X_train) / (len(X_train) + len(X_test))) * 100, 2), \"%\")\n",
    "print(\"X_test: \", round((len(X_test) / (len(X_train) + len(X_test))) * 100, 2), \"%\")\n",
    "print(\"y_train: \", round((len(y_train) / (len(y_train) + len(y_test))) * 100, 2), \"%\")\n",
    "print(\"y_test: \", round((len(y_test) / (len(y_train) + len(y_test))) * 100, 2), \"%\")\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "best_feature_combination = None\n",
    "\n",
    "# Iterate through all possible feature combinations\n",
    "for i in tqdm(range(1, len(features) + 1)):\n",
    "    for subset in combinations(features, i):\n",
    "        selected_features = list(subset)\n",
    "        X_train_subset = X_train[selected_features]\n",
    "        X_test_subset = X_test[selected_features]\n",
    "        \n",
    "        # Define hyperparameters and their possible values to search\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'penalty': ['l2']\n",
    "        }\n",
    "        \n",
    "        # Create a Logistic Regression model\n",
    "        model = LogisticRegression(solver='liblinear')\n",
    "        \n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "        grid_search.fit(X_train_subset, y_train)\n",
    "        \n",
    "        # Get the best parameters and the best model\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        accuracy = best_model.score(X_test_subset, y_test)\n",
    "        \n",
    "        # Check if this combination is the best so far\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_feature_combination = selected_features\n",
    "            best_hyperparameters = best_params\n",
    "\n",
    "print(\"Best Feature Combination:\", best_feature_combination)\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Model Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 year offset results\n",
    "\n",
    "Best Feature Combination: ['averageTurnovers', 'averageFTRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "\n",
    "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
    "\n",
    "Best Model Accuracy: 0.7777777777777778\n",
    "\n",
    "#### 2 year offset results\n",
    "\n",
    "Best Feature Combination: ['averageBlocks', 'averageFGRatio', 'averageFTRatio']\n",
    "\n",
    "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
    "\n",
    "Best Model Accuracy: 0.7777777777777778\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning on split by years (train on latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  85.45 %\n",
      "X_test:  14.55 %\n",
      "y_train:  85.45 %\n",
      "y_test:  14.55 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [02:32<00:00, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Combination: ['averagePoints', 'averageRebounds', 'averageTurnovers', 'numberOfAwardedPlayers']\n",
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Best Model Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['averageWinRate', 'averagePoints', 'averageRebounds', 'averageAssists', \n",
    "            'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio', \n",
    "            'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "\n",
    "target = 'playoff'  \n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "#Split dataset in such way that we use latest years for training and older years for testing\n",
    "X_train=df[df[\"year\"]>3][features]\n",
    "X_test=df[df[\"year\"]<=3][features]\n",
    "y_train=df[df[\"year\"]>3][\"playoff\"]\n",
    "y_test=df[df[\"year\"]<=3][\"playoff\"]\n",
    "\n",
    "# Get percentage of data in each dataset\n",
    "print(\"X_train: \", round((len(X_train) / (len(X_train) + len(X_test))) * 100, 2), \"%\")\n",
    "print(\"X_test: \", round((len(X_test) / (len(X_train) + len(X_test))) * 100, 2), \"%\")\n",
    "print(\"y_train: \", round((len(y_train) / (len(y_train) + len(y_test))) * 100, 2), \"%\")\n",
    "print(\"y_test: \", round((len(y_test) / (len(y_train) + len(y_test))) * 100, 2), \"%\")\n",
    "\n",
    "best_accuracy = 0\n",
    "best_feature_combination = None\n",
    "\n",
    "# Iterate through all possible feature combinations\n",
    "for i in tqdm(range(1, len(features) + 1)):\n",
    "    for subset in combinations(features, i):\n",
    "        selected_features = list(subset)\n",
    "        X_train_subset = X_train[selected_features]\n",
    "        X_test_subset = X_test[selected_features]\n",
    "        \n",
    "        # Define hyperparameters and their possible values to search\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'penalty': ['l2']\n",
    "        }\n",
    "        \n",
    "        # Create a Logistic Regression model\n",
    "        model = LogisticRegression(solver='liblinear')\n",
    "        \n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "        grid_search.fit(X_train_subset, y_train)\n",
    "        \n",
    "        # Get the best parameters and the best model\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        accuracy = best_model.score(X_test_subset, y_test)\n",
    "        \n",
    "        # Check if this combination is the best so far\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_feature_combination = selected_features\n",
    "            best_hyperparameters = best_params\n",
    "\n",
    "print(\"Best Feature Combination:\", best_feature_combination)\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Model Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different approach to hyperparam tuning\n",
    "\n",
    "Saves results to file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training...\n",
    "from itertools import combinations, product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assume df is your DataFrame\n",
    "# Define features and target\n",
    "features = ['averageWinRate', 'averagePoints', 'averageRebounds', 'averageAssists',\n",
    "            'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio',\n",
    "            'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "target = 'playoff'\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train = df[df[\"year\"] < 7][features + ['year']]\n",
    "X_test = df[df[\"year\"] >= 7][features + ['year']]\n",
    "y_train = df[df[\"year\"] < 7][\"playoff\"]\n",
    "y_test = df[df[\"year\"] >= 7][\"playoff\"]\n",
    "\n",
    "df_year_only_train = X_train[\"year\"]\n",
    "df_year_only_test = X_test[\"year\"]\n",
    "\n",
    "best_accuracy_sum = 0\n",
    "best_feature_combination = None\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "all_params = [dict(zip(param_grid, v)) for v in product(*param_grid.values())]\n",
    "\n",
    "# Iterate through all possible feature combinations with 2 to 6 features\n",
    "results = []\n",
    "for subset in tqdm(combinations(features, 4), desc=\"Feature Combinations\"):\n",
    "    selected_features = list(subset) + ['year']\n",
    "\n",
    "    X_train_subset = X_train[selected_features]\n",
    "    X_test_subset = X_test[selected_features]\n",
    "\n",
    "    for params in all_params:\n",
    "        model = LogisticRegression(**params)\n",
    "        model.fit(X_train_subset, y_train)\n",
    "\n",
    "        accuracy_test = accuracy_score(y_test, model.predict(X_test_subset))\n",
    "        accuracy_train = accuracy_score(y_train, model.predict(X_train_subset))\n",
    "\n",
    "        if accuracy_test > 0.75:\n",
    "            results.append({\n",
    "                'acc_train': accuracy_train,\n",
    "                'acc_test': accuracy_test,\n",
    "                'best_feature_combination': str(selected_features),\n",
    "                'best_hyperparameters': str(params)\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "df_cd_json = results_df.to_json(orient=\"records\")\n",
    "new_file = open(\"./datasets/generated/logreg_hyper_param_tuning_2.json\", \"w\")\n",
    "new_file.writelines(df_cd_json)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 year offset results\n",
    "\n",
    "Best Feature Combination: ['averageAssists', 'averageFGRatio', 'numberOfAwardedPlayers']\n",
    "\n",
    "Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n",
    "\n",
    "Best Model Accuracy: 0.8125\n",
    "\n",
    "#### 2 year offset results\n",
    "\n",
    "Best Feature Combination: ['averagePoints', 'averageRebounds', 'averageTurnovers', 'numberOfAwardedPlayers']\n",
    "\n",
    "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
    "\n",
    "Best Model Accuracy: 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Combinations 2: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['year'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Fakultet\\Master\\erasmus\\ML\\FEUP_ML_G79_basketball_playoffs\\code\\04_hyper_param_testing.ipynb Cell 23\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Fakultet/Master/erasmus/ML/FEUP_ML_G79_basketball_playoffs/code/04_hyper_param_testing.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#this way year is always included\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Fakultet/Master/erasmus/ML/FEUP_ML_G79_basketball_playoffs/code/04_hyper_param_testing.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m selected_features\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Fakultet/Master/erasmus/ML/FEUP_ML_G79_basketball_playoffs/code/04_hyper_param_testing.ipynb#X31sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m X_train_subset \u001b[39m=\u001b[39m X_train[selected_features]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Fakultet/Master/erasmus/ML/FEUP_ML_G79_basketball_playoffs/code/04_hyper_param_testing.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m X_test_subset \u001b[39m=\u001b[39m X_test[selected_features]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Fakultet/Master/erasmus/ML/FEUP_ML_G79_basketball_playoffs/code/04_hyper_param_testing.ipynb#X31sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m params \u001b[39min\u001b[39;00m all_params:\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3900\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3901\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3902\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3904\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['year'] not in index\""
     ]
    }
   ],
   "source": [
    "from itertools import combinations, product\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "features = ['averageWinRate', 'averagePoints', 'averageRebounds', 'averageAssists',\n",
    "            'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio',\n",
    "            'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers',]\n",
    "target = 'playoff'\n",
    "\n",
    "#split data\n",
    "X_train = df[df[\"year\"] < 7][features + ['year']]\n",
    "X_test = df[df[\"year\"] >= 7][features + ['year']]\n",
    "y_train = df[df[\"year\"] < 7][\"playoff\"]\n",
    "y_test = df[df[\"year\"] >= 7][\"playoff\"]\n",
    "\n",
    "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "#generate all combinations of the parameters\n",
    "all_params = [dict(zip(grid_params, v)) for v in product(*grid_params.values())]\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['acc_train', 'acc_test', 'best_feature_combination', 'best_hyperparameters'])\n",
    "\n",
    "for num_features in range(2, 7): \n",
    "    for subset in tqdm(combinations(features, num_features), desc=f\"Feature Combinations {num_features}\"):\n",
    "        selected_features = list(subset)\n",
    "        #this way year is always included\n",
    "        selected_features.append('year')\n",
    "\n",
    "        X_train_subset = X_train[selected_features]\n",
    "        X_test_subset = X_test[selected_features]\n",
    "\n",
    "        for params in all_params:\n",
    "\n",
    "            model = KNeighborsClassifier(**params)\n",
    "            model.fit(X_train_subset, y_train)\n",
    "\n",
    "            #evaluate the model\n",
    "            y_pred_test = model.predict(X_test_subset)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "            y_pred_train = model.predict(X_train_subset)\n",
    "            accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "            if accuracy_test > 0.65:\n",
    "                temp_row = pd.DataFrame([{\n",
    "                    'acc_train': accuracy_train,\n",
    "                    'acc_test': accuracy_test,\n",
    "                    'best_feature_combination': str(selected_features),\n",
    "                    'best_hyperparameters': str(params)\n",
    "                }])\n",
    "                results = pd.concat([results, temp_row])\n",
    "\n",
    "# Save the results to a JSON file\n",
    "df_cd_json = results.to_json(orient=\"records\")\n",
    "new_file = open(\"./datasets/generated/knn_hyper_param_tuning.json\", \"w\")\n",
    "new_file.writelines(df_cd_json)\n",
    "new_file.close()\n",
    "\n",
    "results.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Combinations: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "from itertools import combinations, product\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assume df is your DataFrame\n",
    "# Define features and target\n",
    "features = ['averageWinRate', 'averagePoints', 'averageRebounds', 'averageAssists',\n",
    "            'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio',\n",
    "            'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "target = 'playoff'\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train = df[df[\"year\"] < 7][features + ['year']]\n",
    "X_test = df[df[\"year\"] >= 7][features + ['year']]\n",
    "y_train = df[df[\"year\"] < 7][\"playoff\"]\n",
    "y_test = df[df[\"year\"] >= 7][\"playoff\"]\n",
    "\n",
    "df_year_only_train = X_train[\"year\"]\n",
    "df_year_only_test = X_test[\"year\"]\n",
    "\n",
    "model = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
    "}\n",
    " \n",
    "best_accuracy_sum = 0\n",
    "best_feature_combination = None\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "all_params = [dict(zip(param_grid, v)) for v in product(*param_grid.values())]\n",
    "\n",
    "# Iterate through all possible feature combinations with 2 to 6 features\n",
    "results = pd.DataFrame(columns=['acc_train', 'acc_test', 'best_feature_combination', 'best_hyperparameters'])\n",
    "\n",
    "# Always include 'year\n",
    "\n",
    "for subset in tqdm(combinations(features, 4), desc=\"Feature Combinations\"):\n",
    "    selected_features = list(subset) + ['year']\n",
    "\n",
    "    X_train_subset = X_train[selected_features]\n",
    "    X_test_subset = X_test[selected_features]\n",
    "\n",
    "    for params in all_params:\n",
    "       \n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train_subset, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        test_accuracy = best_model.score(X_test, y_test)\n",
    "        \n",
    "        accuracy_test = best_model.score(y_test, model.predict(X_test_subset))\n",
    "        accuracy_train = best_model.score(y_train, model.predict(X_train_subset))\n",
    "\n",
    "        results.append({\n",
    "            'acc_train': accuracy_train,\n",
    "            'acc_test': accuracy_test,\n",
    "            'best_feature_combination': str(selected_features),\n",
    "            'best_hyperparameters': str(best_model)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df\n",
    "\n",
    "df_cd_json = results_df.to_json(orient=\"records\")\n",
    "new_file = open(\"./datasets/generated/svm_hyper_param_tuning.json\", \"w\")\n",
    "new_file.writelines(df_cd_json)\n",
    "new_file.close()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "| Split | Year offset | Best feature combination | Best hyperparameters | Best model accuracy |\n",
    "| ----- | ----------- | ------------------------ | -------------------- | ------------------- |\n",
    "| Random split (70% train, 30% test) | 1 | 'averageWinRate', 'averageRebounds', 'averageAssists', 'averageTurnovers', 'averageFGRatio', 'coachWinRate' | {'C': 1, 'penalty': 'l2'} | 81.58% |\n",
    "| Split by years, train on oldest 7 years | 1 | 'averageSteals', 'numberOfAwardedPlayers' | {'C': 10, 'penalty': 'l2'} | 72.5% |\n",
    "| Split by years, train on latest 7 years | 1 | 'averageAssists', 'averageFGRatio', 'numberOfAwardedPlayers' | {'C': 10, 'penalty': 'l2'} | 81.25% |\n",
    "\n",
    "\n",
    "By comparing the models' accuracy, we can see that the fine tuned model with the random split has the greatest accuracy of 81.58%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
