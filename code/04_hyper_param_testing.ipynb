{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter testing\n",
    "\n",
    "In this section of the code we will try to fine tune our model to get better results.\n",
    "\n",
    "<hr />\n",
    "\n",
    "Import cleaned and aggreated data from [02_data_cleaning_and_aggregation.ipynb](./02_data_cleaning_and_aggregation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_json(\"./datasets/generated/cleaned_aggregated_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>averageWinRate</th>\n",
       "      <th>averagePoints</th>\n",
       "      <th>averageRebounds</th>\n",
       "      <th>averageAssists</th>\n",
       "      <th>averageSteals</th>\n",
       "      <th>averageBlocks</th>\n",
       "      <th>averageTurnovers</th>\n",
       "      <th>averageFGRatio</th>\n",
       "      <th>averageFTRatio</th>\n",
       "      <th>averageThreeRatio</th>\n",
       "      <th>coachWinRate</th>\n",
       "      <th>numberOfAwardedPlayers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>189.512143</td>\n",
       "      <td>84.572143</td>\n",
       "      <td>42.982857</td>\n",
       "      <td>19.696786</td>\n",
       "      <td>7.073929</td>\n",
       "      <td>44.290357</td>\n",
       "      <td>0.408655</td>\n",
       "      <td>0.717564</td>\n",
       "      <td>0.306577</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WAS</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>189.708943</td>\n",
       "      <td>82.593336</td>\n",
       "      <td>36.207412</td>\n",
       "      <td>20.147909</td>\n",
       "      <td>8.820809</td>\n",
       "      <td>38.090105</td>\n",
       "      <td>0.402735</td>\n",
       "      <td>0.800336</td>\n",
       "      <td>0.276818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAS</td>\n",
       "      <td>8</td>\n",
       "      <td>N</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>239.624444</td>\n",
       "      <td>95.275556</td>\n",
       "      <td>50.680741</td>\n",
       "      <td>25.660000</td>\n",
       "      <td>10.042222</td>\n",
       "      <td>44.559259</td>\n",
       "      <td>0.434105</td>\n",
       "      <td>0.760861</td>\n",
       "      <td>0.303131</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAS</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>216.456929</td>\n",
       "      <td>88.321161</td>\n",
       "      <td>42.381086</td>\n",
       "      <td>23.959738</td>\n",
       "      <td>8.204120</td>\n",
       "      <td>39.441011</td>\n",
       "      <td>0.422553</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.337256</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAS</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>193.306310</td>\n",
       "      <td>92.482727</td>\n",
       "      <td>39.100875</td>\n",
       "      <td>21.625518</td>\n",
       "      <td>11.273146</td>\n",
       "      <td>39.394288</td>\n",
       "      <td>0.429846</td>\n",
       "      <td>0.706172</td>\n",
       "      <td>0.334885</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>CHA</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>217.947214</td>\n",
       "      <td>88.550063</td>\n",
       "      <td>49.340595</td>\n",
       "      <td>23.384583</td>\n",
       "      <td>9.538333</td>\n",
       "      <td>38.548387</td>\n",
       "      <td>0.413633</td>\n",
       "      <td>0.758494</td>\n",
       "      <td>0.312949</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>CHA</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>167.550824</td>\n",
       "      <td>73.576923</td>\n",
       "      <td>39.324863</td>\n",
       "      <td>17.955357</td>\n",
       "      <td>8.519231</td>\n",
       "      <td>37.429258</td>\n",
       "      <td>0.380137</td>\n",
       "      <td>0.774988</td>\n",
       "      <td>0.294400</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>CHA</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>205.724760</td>\n",
       "      <td>77.169872</td>\n",
       "      <td>57.090144</td>\n",
       "      <td>23.515625</td>\n",
       "      <td>7.609375</td>\n",
       "      <td>44.546474</td>\n",
       "      <td>0.421223</td>\n",
       "      <td>0.750754</td>\n",
       "      <td>0.273636</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>221.436923</td>\n",
       "      <td>105.233846</td>\n",
       "      <td>44.233846</td>\n",
       "      <td>25.540000</td>\n",
       "      <td>11.933846</td>\n",
       "      <td>44.327692</td>\n",
       "      <td>0.431086</td>\n",
       "      <td>0.707394</td>\n",
       "      <td>0.299977</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>ATL</td>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>153.466144</td>\n",
       "      <td>67.967382</td>\n",
       "      <td>32.125929</td>\n",
       "      <td>15.554088</td>\n",
       "      <td>6.998348</td>\n",
       "      <td>32.590421</td>\n",
       "      <td>0.409914</td>\n",
       "      <td>0.711212</td>\n",
       "      <td>0.363738</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year playoff  averageWinRate  averagePoints  averageRebounds  \\\n",
       "0    WAS    10       Y        0.294118     189.512143        84.572143   \n",
       "1    WAS     9       N        0.470588     189.708943        82.593336   \n",
       "2    WAS     8       N        0.529412     239.624444        95.275556   \n",
       "3    WAS     7       Y        0.470588     216.456929        88.321161   \n",
       "4    WAS     6       N        0.500000     193.306310        92.482727   \n",
       "..   ...   ...     ...             ...            ...              ...   \n",
       "121  CHA     4       Y        0.562500     217.947214        88.550063   \n",
       "122  CHA     3       Y        0.562500     167.550824        73.576923   \n",
       "123  CHA     2       Y        0.250000     205.724760        77.169872   \n",
       "124  ATL    10       Y        0.117647     221.436923       105.233846   \n",
       "125  ATL     9       N        0.500000     153.466144        67.967382   \n",
       "\n",
       "     averageAssists  averageSteals  averageBlocks  averageTurnovers  \\\n",
       "0         42.982857      19.696786       7.073929         44.290357   \n",
       "1         36.207412      20.147909       8.820809         38.090105   \n",
       "2         50.680741      25.660000      10.042222         44.559259   \n",
       "3         42.381086      23.959738       8.204120         39.441011   \n",
       "4         39.100875      21.625518      11.273146         39.394288   \n",
       "..              ...            ...            ...               ...   \n",
       "121       49.340595      23.384583       9.538333         38.548387   \n",
       "122       39.324863      17.955357       8.519231         37.429258   \n",
       "123       57.090144      23.515625       7.609375         44.546474   \n",
       "124       44.233846      25.540000      11.933846         44.327692   \n",
       "125       32.125929      15.554088       6.998348         32.590421   \n",
       "\n",
       "     averageFGRatio  averageFTRatio  averageThreeRatio  coachWinRate  \\\n",
       "0          0.408655        0.717564           0.306577      0.500000   \n",
       "1          0.402735        0.800336           0.276818      0.500000   \n",
       "2          0.434105        0.760861           0.303131      0.529412   \n",
       "3          0.422553        0.743379           0.337256      0.470588   \n",
       "4          0.429846        0.706172           0.334885      0.437500   \n",
       "..              ...             ...                ...           ...   \n",
       "121        0.413633        0.758494           0.312949      0.500000   \n",
       "122        0.380137        0.774988           0.294400      0.562500   \n",
       "123        0.421223        0.750754           0.273636      0.281250   \n",
       "124        0.431086        0.707394           0.299977      0.117647   \n",
       "125        0.409914        0.711212           0.363738      0.500000   \n",
       "\n",
       "     numberOfAwardedPlayers  \n",
       "0                         0  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  \n",
       "..                      ...  \n",
       "121                       0  \n",
       "122                       0  \n",
       "123                       0  \n",
       "124                       5  \n",
       "125                       2  \n",
       "\n",
       "[126 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter testing some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7368421052631579\n",
      "SVM Accuracy: 0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are your training and testing data\n",
    "# X_train and X_test should be your feature matrices, and y_train and y_test should be your target labels (0 or 1)\n",
    "features=['averagePoints','averageRebounds','averageAssists','averageFGRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "target = 'playoff'\n",
    "x = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_predictions = logreg.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear')  # You can change the kernel as needed (e.g., 'rbf' for radial basis function)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_predictions = svm.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter testing all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6842105263157895\n",
      "SVM Accuracy: 0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are your training and testing data\n",
    "# X_train and X_test should be your feature matrices, and y_train and y_test should be your target labels (0 or 1)\n",
    "features=['averageWinRate', 'averagePoints','averageRebounds','averageAssists', 'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio', 'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "target = 'playoff'\n",
    "x = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_predictions = logreg.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear')  # You can change the kernel as needed (e.g., 'rbf' for radial basis function)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_predictions = svm.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Combination: ['averageWinRate', 'averageRebounds', 'averageAssists', 'averageTurnovers', 'averageFGRatio', 'coachWinRate']\n",
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2'}\n",
      "Best Model Accuracy: 0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "features = ['averageWinRate', 'averagePoints', 'averageRebounds', 'averageAssists', \n",
    "            'averageSteals', 'averageBlocks', 'averageTurnovers', 'averageFGRatio', \n",
    "            'averageFTRatio', 'averageThreeRatio', 'coachWinRate', 'numberOfAwardedPlayers']\n",
    "\n",
    "target = 'playoff'  \n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_feature_combination = None\n",
    "\n",
    "# Iterate through all possible feature combinations\n",
    "for i in range(1, len(features) + 1):\n",
    "    for subset in combinations(features, i):\n",
    "        selected_features = list(subset)\n",
    "        X_train_subset = X_train[selected_features]\n",
    "        X_test_subset = X_test[selected_features]\n",
    "        \n",
    "        # Define hyperparameters and their possible values to search\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'penalty': ['l2']\n",
    "        }\n",
    "        \n",
    "        # Create a Logistic Regression model\n",
    "        model = LogisticRegression(solver='liblinear')\n",
    "        \n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "        grid_search.fit(X_train_subset, y_train)\n",
    "        \n",
    "        # Get the best parameters and the best model\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        accuracy = best_model.score(X_test_subset, y_test)\n",
    "        \n",
    "        # Check if this combination is the best so far\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_feature_combination = selected_features\n",
    "            best_hyperparameters = best_params\n",
    "\n",
    "print(\"Best Feature Combination:\", best_feature_combination)\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Model Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By comparing the 2 model's accuracy, we can see that the fine tuned model (82%) has a greater accuracy than the base model (62%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
